{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f69ca09",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-07-09T16:02:37.105239Z",
     "iopub.status.busy": "2023-07-09T16:02:37.104892Z",
     "iopub.status.idle": "2023-07-09T16:06:07.062713Z",
     "shell.execute_reply": "2023-07-09T16:06:07.061593Z"
    },
    "papermill": {
     "duration": 209.966427,
     "end_time": "2023-07-09T16:06:07.065180",
     "exception": false,
     "start_time": "2023-07-09T16:02:37.098753",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/facebookresearch/detectron2.git\r\n",
      "  Cloning https://github.com/facebookresearch/detectron2.git to /tmp/pip-req-build-d3bql7c7\r\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/detectron2.git /tmp/pip-req-build-d3bql7c7\r\n",
      "  Resolved https://github.com/facebookresearch/detectron2.git to commit ff53992b1985b63bd3262b5a36167098e3dada02\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: Pillow>=7.1 in /opt/conda/lib/python3.10/site-packages (from detectron2==0.6) (9.5.0)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from detectron2==0.6) (3.6.3)\r\n",
      "Collecting pycocotools>=2.0.2 (from detectron2==0.6)\r\n",
      "  Downloading pycocotools-2.0.6.tar.gz (24 kB)\r\n",
      "  Installing build dependencies ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \bdone\r\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: termcolor>=1.1 in /opt/conda/lib/python3.10/site-packages (from detectron2==0.6) (2.3.0)\r\n",
      "Collecting yacs>=0.1.8 (from detectron2==0.6)\r\n",
      "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\r\n",
      "Requirement already satisfied: tabulate in /opt/conda/lib/python3.10/site-packages (from detectron2==0.6) (0.9.0)\r\n",
      "Requirement already satisfied: cloudpickle in /opt/conda/lib/python3.10/site-packages (from detectron2==0.6) (2.2.1)\r\n",
      "Requirement already satisfied: tqdm>4.29.0 in /opt/conda/lib/python3.10/site-packages (from detectron2==0.6) (4.64.1)\r\n",
      "Requirement already satisfied: tensorboard in /opt/conda/lib/python3.10/site-packages (from detectron2==0.6) (2.12.3)\r\n",
      "Collecting fvcore<0.1.6,>=0.1.5 (from detectron2==0.6)\r\n",
      "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25hCollecting iopath<0.1.10,>=0.1.7 (from detectron2==0.6)\r\n",
      "  Downloading iopath-0.1.9-py3-none-any.whl (27 kB)\r\n",
      "Collecting omegaconf>=2.1 (from detectron2==0.6)\r\n",
      "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting hydra-core>=1.1 (from detectron2==0.6)\r\n",
      "  Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting black (from detectron2==0.6)\r\n",
      "  Downloading black-23.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from detectron2==0.6) (21.3)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (1.23.5)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (5.4.1)\r\n",
      "Collecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.1->detectron2==0.6)\r\n",
      "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25hCollecting portalocker (from iopath<0.1.10,>=0.1.7->detectron2==0.6)\r\n",
      "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->detectron2==0.6) (1.0.7)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->detectron2==0.6) (0.11.0)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->detectron2==0.6) (4.39.3)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->detectron2==0.6) (1.4.4)\r\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->detectron2==0.6) (3.0.9)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->detectron2==0.6) (2.8.2)\r\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from black->detectron2==0.6) (8.1.3)\r\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from black->detectron2==0.6) (1.0.0)\r\n",
      "Collecting packaging (from detectron2==0.6)\r\n",
      "  Downloading packaging-23.1-py3-none-any.whl (48 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting pathspec>=0.9.0 (from black->detectron2==0.6)\r\n",
      "  Downloading pathspec-0.11.1-py3-none-any.whl (29 kB)\r\n",
      "Requirement already satisfied: platformdirs>=2 in /opt/conda/lib/python3.10/site-packages (from black->detectron2==0.6) (3.5.0)\r\n",
      "Requirement already satisfied: tomli>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from black->detectron2==0.6) (2.0.1)\r\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.10/site-packages (from tensorboard->detectron2==0.6) (1.4.0)\r\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /opt/conda/lib/python3.10/site-packages (from tensorboard->detectron2==0.6) (1.51.1)\r\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard->detectron2==0.6) (2.17.3)\r\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard->detectron2==0.6) (1.0.0)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard->detectron2==0.6) (3.4.3)\r\n",
      "Requirement already satisfied: protobuf>=3.19.6 in /opt/conda/lib/python3.10/site-packages (from tensorboard->detectron2==0.6) (3.20.3)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard->detectron2==0.6) (2.28.2)\r\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard->detectron2==0.6) (59.8.0)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard->detectron2==0.6) (0.7.0)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard->detectron2==0.6) (2.3.6)\r\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.10/site-packages (from tensorboard->detectron2==0.6) (0.40.0)\r\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (4.2.4)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.2.7)\r\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (1.16.0)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (4.9)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard->detectron2==0.6) (1.3.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2.1.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (3.4)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (1.26.15)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2023.5.7)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard->detectron2==0.6) (2.1.2)\r\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.4.8)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->detectron2==0.6) (3.2.2)\r\n",
      "Building wheels for collected packages: detectron2, fvcore, antlr4-python3-runtime, pycocotools\r\n",
      "  Building wheel for detectron2 (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for detectron2: filename=detectron2-0.6-cp310-cp310-linux_x86_64.whl size=1262531 sha256=a9b1839b0a00f7a29431d5cae1b85704c8950a953d18a7456d9025ae5b4d911d\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-gnd3n65i/wheels/47/e5/15/94c80df2ba85500c5d76599cc307c0a7079d0e221bb6fc4375\r\n",
      "  Building wheel for fvcore (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61431 sha256=8f16a212235e44535a9b6e43e0aa4679615b6c62333072cc46907f5b32d8bb69\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/01/c0/af/77c1cf53a1be9e42a52b48e5af2169d40ec2e89f7362489dd0\r\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144574 sha256=31a046337935773a7ec47354ebe04bd77830e3061a48a16637d89be74e13fe6b\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\r\n",
      "  Building wheel for pycocotools (pyproject.toml) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for pycocotools: filename=pycocotools-2.0.6-cp310-cp310-linux_x86_64.whl size=93593 sha256=3e44561a2206bb98fb53ef3218bcc0d76a3b5e3334e7a3d1319659c061719242\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/58/e6/f9/f87c8f8be098b51b616871315318329cae12cdb618f4caac93\r\n",
      "Successfully built detectron2 fvcore antlr4-python3-runtime pycocotools\r\n",
      "Installing collected packages: antlr4-python3-runtime, yacs, portalocker, pathspec, packaging, omegaconf, iopath, hydra-core, black, pycocotools, fvcore, detectron2\r\n",
      "  Attempting uninstall: packaging\r\n",
      "    Found existing installation: packaging 21.3\r\n",
      "    Uninstalling packaging-21.3:\r\n",
      "      Successfully uninstalled packaging-21.3\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "cudf 23.6.0 requires cupy-cuda11x>=12.0.0, which is not installed.\r\n",
      "cuml 23.6.0 requires cupy-cuda11x>=12.0.0, which is not installed.\r\n",
      "dask-cudf 23.6.0 requires cupy-cuda11x>=12.0.0, which is not installed.\r\n",
      "cudf 23.6.0 requires protobuf<4.22,>=4.21.6, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "cuml 23.6.0 requires dask==2023.3.2, but you have dask 2023.6.0 which is incompatible.\r\n",
      "dask-cuda 23.6.0 requires dask==2023.3.2, but you have dask 2023.6.0 which is incompatible.\r\n",
      "dask-cudf 23.6.0 requires dask==2023.3.2, but you have dask 2023.6.0 which is incompatible.\r\n",
      "distributed 2023.3.2.1 requires dask==2023.3.2, but you have dask 2023.6.0 which is incompatible.\r\n",
      "google-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 23.1 which is incompatible.\r\n",
      "jupyterlab-lsp 4.2.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "momepy 0.6.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "pymc3 3.11.5 requires numpy<1.22.2,>=1.15.0, but you have numpy 1.23.5 which is incompatible.\r\n",
      "pymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.10.1 which is incompatible.\r\n",
      "raft-dask 23.6.1 requires dask==2023.3.2, but you have dask 2023.6.0 which is incompatible.\r\n",
      "ydata-profiling 4.1.2 requires scipy<1.10,>=1.4.1, but you have scipy 1.10.1 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed antlr4-python3-runtime-4.9.3 black-23.3.0 detectron2-0.6 fvcore-0.1.5.post20221221 hydra-core-1.3.2 iopath-0.1.9 omegaconf-2.3.0 packaging-23.1 pathspec-0.11.1 portalocker-2.7.0 pycocotools-2.0.6 yacs-0.1.8\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!rm -rf detectron2/\n",
    "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "434cb8fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-09T16:06:07.090098Z",
     "iopub.status.busy": "2023-07-09T16:06:07.088588Z",
     "iopub.status.idle": "2023-07-09T16:06:18.541134Z",
     "shell.execute_reply": "2023-07-09T16:06:18.540007Z"
    },
    "papermill": {
     "duration": 11.466653,
     "end_time": "2023-07-09T16:06:18.543349",
     "exception": false,
     "start_time": "2023-07-09T16:06:07.076696",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-07-09 16:06:07--  https://www.dropbox.com/scl/fi/rh10rbi5pa67bgil86o7k/model_final.pth?rlkey=jsvwgi5pr4nbzo6hqvls9epac&dl=0\r\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.9.18, 2620:100:601f:18::a27d:912\r\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.9.18|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 302 Found\r\n",
      "Location: https://www.dropbox.com/e/scl/fi/rh10rbi5pa67bgil86o7k/model_final.pth?dl=0&rlkey=jsvwgi5pr4nbzo6hqvls9epac [following]\r\n",
      "--2023-07-09 16:06:08--  https://www.dropbox.com/e/scl/fi/rh10rbi5pa67bgil86o7k/model_final.pth?dl=0&rlkey=jsvwgi5pr4nbzo6hqvls9epac\r\n",
      "Reusing existing connection to www.dropbox.com:443.\r\n",
      "HTTP request sent, awaiting response... 302 Found\r\n",
      "Location: https://uc2998c5111a2eee6e2bd8513528.dl.dropboxusercontent.com/cd/0/get/B_hPC2nXXR10z7S3Q8TgTy8OLqaDNTaCUBxw9z8xegoukNvpDubK7EpG3bcSLBUE02NdxTQe43iUENasBPBYV74pSiUUbu2fA5fSurBZDerieQjZ5SdpoNvqLjhzUsOPKfyhQZ1a9s_sMsOixyPgqXF5EaclCvQ94q9DpuLp78F8GNvQV5ClDIMLMUMc-X7bXcc/file# [following]\r\n",
      "--2023-07-09 16:06:08--  https://uc2998c5111a2eee6e2bd8513528.dl.dropboxusercontent.com/cd/0/get/B_hPC2nXXR10z7S3Q8TgTy8OLqaDNTaCUBxw9z8xegoukNvpDubK7EpG3bcSLBUE02NdxTQe43iUENasBPBYV74pSiUUbu2fA5fSurBZDerieQjZ5SdpoNvqLjhzUsOPKfyhQZ1a9s_sMsOixyPgqXF5EaclCvQ94q9DpuLp78F8GNvQV5ClDIMLMUMc-X7bXcc/file\r\n",
      "Resolving uc2998c5111a2eee6e2bd8513528.dl.dropboxusercontent.com (uc2998c5111a2eee6e2bd8513528.dl.dropboxusercontent.com)... 162.125.9.15, 2620:100:601f:15::a27d:90f\r\n",
      "Connecting to uc2998c5111a2eee6e2bd8513528.dl.dropboxusercontent.com (uc2998c5111a2eee6e2bd8513528.dl.dropboxusercontent.com)|162.125.9.15|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 1235576737 (1.2G) [application/binary]\r\n",
      "Saving to: ‘model.pth’\r\n",
      "\r\n",
      "model.pth           100%[===================>]   1.15G   123MB/s    in 9.0s    \r\n",
      "\r\n",
      "2023-07-09 16:06:18 (130 MB/s) - ‘model.pth’ saved [1235576737/1235576737]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!wget 'https://www.dropbox.com/scl/fi/rh10rbi5pa67bgil86o7k/model_final.pth?rlkey=jsvwgi5pr4nbzo6hqvls9epac&dl=0' -O model.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbfc5ab8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-09T16:06:18.573944Z",
     "iopub.status.busy": "2023-07-09T16:06:18.573596Z",
     "iopub.status.idle": "2023-07-09T16:06:20.711521Z",
     "shell.execute_reply": "2023-07-09T16:06:20.710602Z"
    },
    "papermill": {
     "duration": 2.15618,
     "end_time": "2023-07-09T16:06:20.714015",
     "exception": false,
     "start_time": "2023-07-09T16:06:18.557835",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "from detectron2.config import LazyConfig, instantiate\n",
    "from detectron2.engine import (\n",
    "    AMPTrainer,\n",
    "    SimpleTrainer,\n",
    "    default_argument_parser,\n",
    "    default_setup,\n",
    "    default_writers,\n",
    "    hooks,\n",
    "    launch\n",
    ")\n",
    "from detectron2.engine.defaults import _try_get_key\n",
    "from detectron2.engine.defaults import create_ddp_model\n",
    "from detectron2.evaluation import inference_on_dataset, print_csv_format\n",
    "from detectron2.utils import comm\n",
    "\n",
    "from functools import partial\n",
    "from detectron2.utils.file_io import PathManager\n",
    "from omegaconf import OmegaConf\n",
    "import torch.nn as nn\n",
    "from fvcore.common.param_scheduler import MultiStepParamScheduler\n",
    "\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.config import LazyCall as L\n",
    "from detectron2.solver import WarmupParamScheduler\n",
    "from detectron2.modeling import MViT\n",
    "from detectron2.layers import ShapeSpec\n",
    "from detectron2.modeling.box_regression import Box2BoxTransform\n",
    "from detectron2.modeling.matcher import Matcher\n",
    "from detectron2.modeling.roi_heads import (\n",
    "    FastRCNNOutputLayers,\n",
    "    FastRCNNConvFCHead,\n",
    "    CascadeROIHeads,\n",
    ")\n",
    "from detectron2.utils.env import seed_all_rng\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "import detectron2.data.transforms as T\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.config import LazyCall as L\n",
    "import detectron2.data.transforms as T\n",
    "from detectron2.config import LazyCall as L\n",
    "from detectron2.data import (\n",
    "    DatasetMapper,\n",
    "    build_detection_test_loader,\n",
    "    build_detection_train_loader,\n",
    "    get_detection_dataset_dicts,\n",
    ")\n",
    "from detectron2.evaluation import COCOEvaluator\n",
    "from detectron2.utils.logger import setup_logger\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "from detectron2.config import LazyConfig, instantiate\n",
    "from detectron2.data.detection_utils import read_image\n",
    "from detectron2.utils.logger import setup_logger\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "import atexit\n",
    "import bisect\n",
    "from copy import copy\n",
    "import multiprocessing as mp\n",
    "from collections import deque\n",
    "import cv2\n",
    "import torch\n",
    "\n",
    "import detectron2.data.transforms as T\n",
    "from detectron2.data import MetadataCatalog\n",
    "from detectron2.structures import Instances\n",
    "from detectron2.utils.video_visualizer import VideoVisualizer\n",
    "from detectron2.utils.visualizer import ColorMode, Visualizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7889a95e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-09T16:06:20.744626Z",
     "iopub.status.busy": "2023-07-09T16:06:20.743530Z",
     "iopub.status.idle": "2023-07-09T16:06:20.748819Z",
     "shell.execute_reply": "2023-07-09T16:06:20.747999Z"
    },
    "papermill": {
     "duration": 0.022372,
     "end_time": "2023-07-09T16:06:20.750777",
     "exception": false,
     "start_time": "2023-07-09T16:06:20.728405",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "register_coco_instances(\"badlad_train\", {}, '/kaggle/input/dlsprint2/badlad/labels/coco_format/train/badlad-train-coco.json', '/kaggle/input/dlsprint2/badlad/images/train')\n",
    "register_coco_instances(\"badlad_test\", {}, '/kaggle/input/dlsprint2/badlad/badlad-test-metadata.json', '/kaggle/input/dlsprint2/badlad/images/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf661785",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-09T16:06:20.780597Z",
     "iopub.status.busy": "2023-07-09T16:06:20.780333Z",
     "iopub.status.idle": "2023-07-09T16:06:20.802950Z",
     "shell.execute_reply": "2023-07-09T16:06:20.802136Z"
    },
    "papermill": {
     "duration": 0.039992,
     "end_time": "2023-07-09T16:06:20.804970",
     "exception": false,
     "start_time": "2023-07-09T16:06:20.764978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def setup():\n",
    "    model = model_zoo.get_config(\"common/models/mask_rcnn_fpn.py\").model\n",
    "    constants = model_zoo.get_config(\"common/data/constants.py\").constants\n",
    "    model.pixel_mean = constants.imagenet_rgb256_mean\n",
    "    model.pixel_std = constants.imagenet_rgb256_std\n",
    "    model.input_format = \"RGB\"\n",
    "    model.backbone.bottom_up = L(MViT)(\n",
    "        embed_dim=96,\n",
    "        depth=24,\n",
    "        num_heads=1,\n",
    "        last_block_indexes=(1, 4, 20, 23),\n",
    "        residual_pooling=True,\n",
    "        drop_path_rate=0.4,\n",
    "        norm_layer=partial(nn.LayerNorm, eps=1e-6),\n",
    "        out_features=(\"scale2\", \"scale3\", \"scale4\", \"scale5\"),\n",
    "    )\n",
    "    model.backbone.in_features = \"${.bottom_up.out_features}\"\n",
    "    model.backbone.square_pad = 1024\n",
    "\n",
    "    # New heads and LN\n",
    "    model.backbone.norm = \"LN\"  # Use LN in FPN\n",
    "    model.roi_heads.box_head.conv_norm = model.roi_heads.mask_head.conv_norm = \"LN\"\n",
    "\n",
    "    # 2conv in RPN:\n",
    "    model.proposal_generator.head.conv_dims = [-1, -1]\n",
    "\n",
    "    # arguments that don't exist for Cascade R-CNN\n",
    "    [model.roi_heads.pop(k) for k in [\"box_head\", \"box_predictor\", \"proposal_matcher\"]]\n",
    "    model.roi_heads.update(\n",
    "        _target_=CascadeROIHeads,\n",
    "        box_heads=[\n",
    "            L(FastRCNNConvFCHead)(\n",
    "                input_shape=ShapeSpec(channels=256, height=7, width=7),\n",
    "                conv_dims=[256, 256, 256, 256],\n",
    "                fc_dims=[1024],\n",
    "                conv_norm=\"LN\",\n",
    "            )\n",
    "            for _ in range(3)\n",
    "        ],\n",
    "        box_predictors=[\n",
    "            L(FastRCNNOutputLayers)(\n",
    "                input_shape=ShapeSpec(channels=1024),\n",
    "                test_score_thresh=0.05,\n",
    "                box2box_transform=L(Box2BoxTransform)(weights=(w1, w1, w2, w2)),\n",
    "                cls_agnostic_bbox_reg=True,\n",
    "                num_classes=\"${...num_classes}\",\n",
    "            )\n",
    "            for (w1, w2) in [(10, 5), (20, 10), (30, 15)]\n",
    "        ],\n",
    "        proposal_matchers=[\n",
    "            L(Matcher)(thresholds=[th], labels=[0, 1], allow_low_quality_matches=False)\n",
    "            for th in [0.5, 0.6, 0.7]\n",
    "        ],\n",
    "    )\n",
    "    model.roi_heads.num_classes = 4\n",
    "    model.roi_heads.batch_size_per_image = 512\n",
    "\n",
    "    dataloader = OmegaConf.create()\n",
    "\n",
    "    image_size = 1024\n",
    "    dataloader.train = L(build_detection_train_loader)(\n",
    "        dataset=L(get_detection_dataset_dicts)(names=\"badlad_train\"),\n",
    "        mapper=L(DatasetMapper)(\n",
    "            is_train=True,\n",
    "            augmentations=[\n",
    "                L(T.RandomBrightness)(intensity_min=0.8,intensity_max=1.2),\n",
    "                L(T.RandomContrast)(intensity_min=0.5,intensity_max=1.5),\n",
    "                L(T.RandomSaturation)(intensity_min=0.5,intensity_max=1.0),\n",
    "                L(T.RandomRotation)(angle=[-5, 5], sample_style=\"range\"),\n",
    "                L(T.ResizeScale)(\n",
    "                    min_scale=0.1, max_scale=2.0, target_width=image_size, target_height=image_size\n",
    "                ),\n",
    "                L(T.FixedSizeCrop)(crop_size=(image_size, image_size), pad=False),\n",
    "            ],\n",
    "            image_format=\"RGB\",\n",
    "            use_instance_mask=True,\n",
    "        ),\n",
    "        total_batch_size=16,\n",
    "        num_workers=4,\n",
    "    )\n",
    "\n",
    "    dataloader.test = L(build_detection_test_loader)(\n",
    "        dataset=L(get_detection_dataset_dicts)(names=\"badlad_test\", filter_empty=False),\n",
    "        mapper=L(DatasetMapper)(\n",
    "            is_train=False,\n",
    "            augmentations=[\n",
    "                L(T.ResizeShortestEdge)(short_edge_length=image_size, max_size=image_size),\n",
    "            ],\n",
    "            image_format=\"RGB\",\n",
    "        ),\n",
    "        num_workers=2,\n",
    "    )\n",
    "\n",
    "    dataloader.evaluator = L(COCOEvaluator)(\n",
    "        dataset_name=\"${..test.dataset.names}\",\n",
    "    )\n",
    "\n",
    "    dataloader.train.num_workers = 2\n",
    "    dataloader.train.total_batch_size = 16\n",
    "    # recompute boxes due to cropping\n",
    "    dataloader.train.mapper.recompute_boxes = True\n",
    "\n",
    "    # Initialization and trainer settings\n",
    "    train = model_zoo.get_config(\"common/train.py\").train\n",
    "    train.amp.enabled = True\n",
    "    train.ddp.fp16_compression = True\n",
    "    train.init_checkpoint = \"detectron2://ImageNetPretrained/mvitv2/MViTv2_B_in21k.pyth\"\n",
    "    train.output_dir = \"./output/mvit2b\"\n",
    "    # Schedule\n",
    "    # 12 epoch\n",
    "    train.max_iter = 15274\n",
    "    train.eval_period = 1000\n",
    "    train.log_period = 20\n",
    "    train.checkpointer.period = 1000\n",
    "    train.device = \"cuda\"\n",
    "\n",
    "    lr_multiplier = L(WarmupParamScheduler)(\n",
    "        scheduler=L(MultiStepParamScheduler)(\n",
    "            values=[1.0, 0.1, 0.01],\n",
    "            milestones=[13577, 14816],\n",
    "            num_updates=train.max_iter,\n",
    "        ),\n",
    "        warmup_length=50 / train.max_iter,\n",
    "        warmup_factor=0.001,\n",
    "    )\n",
    "\n",
    "    optimizer = model_zoo.get_config(\"common/optim.py\").AdamW\n",
    "    optimizer.params.overrides = {\"pos_embed\": {\"weight_decay\": 0.0}}\n",
    "    optimizer.lr = 0.00008\n",
    "\n",
    "    dataloader.evaluator.output_dir = train.output_dir\n",
    "\n",
    "    cfg = OmegaConf.create()\n",
    "    cfg.model = model\n",
    "    cfg.dataloader = dataloader\n",
    "    cfg.train = train\n",
    "    cfg.optimizer = optimizer\n",
    "    cfg.lr_multiplier = lr_multiplier\n",
    "\n",
    "    return cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92ad6d44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-09T16:06:20.834182Z",
     "iopub.status.busy": "2023-07-09T16:06:20.833913Z",
     "iopub.status.idle": "2023-07-09T16:06:21.797457Z",
     "shell.execute_reply": "2023-07-09T16:06:21.796161Z"
    },
    "papermill": {
     "duration": 0.981174,
     "end_time": "2023-07-09T16:06:21.800339",
     "exception": false,
     "start_time": "2023-07-09T16:06:20.819165",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!export LRU_CACHE_CAPACITY=1\n",
    "ACCEPTANCE_THRESHOLD=0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1e35538",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-09T16:06:21.831168Z",
     "iopub.status.busy": "2023-07-09T16:06:21.830303Z",
     "iopub.status.idle": "2023-07-09T16:06:21.835479Z",
     "shell.execute_reply": "2023-07-09T16:06:21.834609Z"
    },
    "papermill": {
     "duration": 0.022651,
     "end_time": "2023-07-09T16:06:21.837466",
     "exception": false,
     "start_time": "2023-07-09T16:06:21.814815",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF']='max_split_size_mb:512'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b799132",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-09T16:06:21.867246Z",
     "iopub.status.busy": "2023-07-09T16:06:21.866415Z",
     "iopub.status.idle": "2023-07-09T16:06:22.827919Z",
     "shell.execute_reply": "2023-07-09T16:06:22.826702Z"
    },
    "papermill": {
     "duration": 0.979543,
     "end_time": "2023-07-09T16:06:22.830831",
     "exception": false,
     "start_time": "2023-07-09T16:06:21.851288",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_split_size_mb:512\r\n"
     ]
    }
   ],
   "source": [
    "!echo $PYTORCH_CUDA_ALLOC_CONF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67e1d046",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-09T16:06:22.863114Z",
     "iopub.status.busy": "2023-07-09T16:06:22.861374Z",
     "iopub.status.idle": "2023-07-09T16:06:31.064659Z",
     "shell.execute_reply": "2023-07-09T16:06:31.063734Z"
    },
    "papermill": {
     "duration": 8.222776,
     "end_time": "2023-07-09T16:06:31.068534",
     "exception": false,
     "start_time": "2023-07-09T16:06:22.845758",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/09 16:06:30 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from model.pth ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GeneralizedRCNN(\n",
       "  (backbone): FPN(\n",
       "    (fpn_lateral2): Conv2d(\n",
       "      96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "      (norm): LayerNorm()\n",
       "    )\n",
       "    (fpn_output2): Conv2d(\n",
       "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "      (norm): LayerNorm()\n",
       "    )\n",
       "    (fpn_lateral3): Conv2d(\n",
       "      192, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "      (norm): LayerNorm()\n",
       "    )\n",
       "    (fpn_output3): Conv2d(\n",
       "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "      (norm): LayerNorm()\n",
       "    )\n",
       "    (fpn_lateral4): Conv2d(\n",
       "      384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "      (norm): LayerNorm()\n",
       "    )\n",
       "    (fpn_output4): Conv2d(\n",
       "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "      (norm): LayerNorm()\n",
       "    )\n",
       "    (fpn_lateral5): Conv2d(\n",
       "      768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "      (norm): LayerNorm()\n",
       "    )\n",
       "    (fpn_output5): Conv2d(\n",
       "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "      (norm): LayerNorm()\n",
       "    )\n",
       "    (top_block): LastLevelMaxPool()\n",
       "    (bottom_up): MViT(\n",
       "      (patch_embed): PatchEmbed(\n",
       "        (proj): Conv2d(3, 96, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))\n",
       "      )\n",
       "      (blocks): ModuleList(\n",
       "        (0): MultiScaleBlock(\n",
       "          (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): MultiScaleAttention(\n",
       "            (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
       "            (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "            (pool_q): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_k): Conv2d(96, 96, kernel_size=(3, 3), stride=(4, 4), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_v): Conv2d(96, 96, kernel_size=(3, 3), stride=(4, 4), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): MultiScaleBlock(\n",
       "          (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): MultiScaleAttention(\n",
       "            (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
       "            (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "            (pool_q): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_k): Conv2d(96, 96, kernel_size=(3, 3), stride=(4, 4), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_v): Conv2d(96, 96, kernel_size=(3, 3), stride=(4, 4), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.017)\n",
       "          (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): MultiScaleBlock(\n",
       "          (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): MultiScaleAttention(\n",
       "            (qkv): Linear(in_features=96, out_features=576, bias=True)\n",
       "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "            (pool_q): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_k): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_v): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.035)\n",
       "          (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (proj): Linear(in_features=96, out_features=192, bias=True)\n",
       "          (pool_skip): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (3): MultiScaleBlock(\n",
       "          (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): MultiScaleAttention(\n",
       "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "            (pool_q): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_k): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_v): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.052)\n",
       "          (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): MultiScaleBlock(\n",
       "          (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): MultiScaleAttention(\n",
       "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "            (pool_q): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_k): Conv2d(96, 96, kernel_size=(3, 3), stride=(4, 4), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_v): Conv2d(96, 96, kernel_size=(3, 3), stride=(4, 4), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.070)\n",
       "          (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): MultiScaleBlock(\n",
       "          (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): MultiScaleAttention(\n",
       "            (qkv): Linear(in_features=192, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (pool_q): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_k): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_v): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.087)\n",
       "          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (proj): Linear(in_features=192, out_features=384, bias=True)\n",
       "          (pool_skip): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (6): MultiScaleBlock(\n",
       "          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): MultiScaleAttention(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (pool_q): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_k): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_v): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.104)\n",
       "          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): MultiScaleBlock(\n",
       "          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): MultiScaleAttention(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (pool_q): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_k): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_v): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.122)\n",
       "          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): MultiScaleBlock(\n",
       "          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): MultiScaleAttention(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (pool_q): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_k): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_v): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.139)\n",
       "          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): MultiScaleBlock(\n",
       "          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): MultiScaleAttention(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (pool_q): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_k): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_v): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.157)\n",
       "          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): MultiScaleBlock(\n",
       "          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): MultiScaleAttention(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (pool_q): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_k): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_v): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.174)\n",
       "          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): MultiScaleBlock(\n",
       "          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): MultiScaleAttention(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (pool_q): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_k): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_v): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.191)\n",
       "          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (12): MultiScaleBlock(\n",
       "          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): MultiScaleAttention(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (pool_q): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_k): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_v): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.209)\n",
       "          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (13): MultiScaleBlock(\n",
       "          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): MultiScaleAttention(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (pool_q): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_k): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_v): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.226)\n",
       "          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (14): MultiScaleBlock(\n",
       "          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): MultiScaleAttention(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (pool_q): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_k): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_v): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.243)\n",
       "          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (15): MultiScaleBlock(\n",
       "          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): MultiScaleAttention(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (pool_q): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_k): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_v): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.261)\n",
       "          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (16): MultiScaleBlock(\n",
       "          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): MultiScaleAttention(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (pool_q): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_k): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_v): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.278)\n",
       "          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (17): MultiScaleBlock(\n",
       "          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): MultiScaleAttention(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (pool_q): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_k): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_v): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.296)\n",
       "          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (18): MultiScaleBlock(\n",
       "          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): MultiScaleAttention(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (pool_q): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_k): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_v): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.313)\n",
       "          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (19): MultiScaleBlock(\n",
       "          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): MultiScaleAttention(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (pool_q): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_k): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_v): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.330)\n",
       "          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (20): MultiScaleBlock(\n",
       "          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): MultiScaleAttention(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (pool_q): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_k): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_v): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.348)\n",
       "          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (21): MultiScaleBlock(\n",
       "          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): MultiScaleAttention(\n",
       "            (qkv): Linear(in_features=384, out_features=2304, bias=True)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (pool_q): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_k): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_v): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.365)\n",
       "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (proj): Linear(in_features=384, out_features=768, bias=True)\n",
       "          (pool_skip): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (22): MultiScaleBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): MultiScaleAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (pool_q): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_k): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_v): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.383)\n",
       "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (23): MultiScaleBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): MultiScaleAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (pool_q): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_k): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_v): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.400)\n",
       "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (scale2_norm): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "      (scale3_norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (scale4_norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (scale5_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (proposal_generator): RPN(\n",
       "    (rpn_head): StandardRPNHead(\n",
       "      (conv): Sequential(\n",
       "        (conv0): Conv2d(\n",
       "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "        (conv1): Conv2d(\n",
       "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (anchor_generator): DefaultAnchorGenerator(\n",
       "      (cell_anchors): BufferList()\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): CascadeROIHeads(\n",
       "    (box_pooler): ROIPooler(\n",
       "      (level_poolers): ModuleList(\n",
       "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
       "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
       "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
       "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
       "      )\n",
       "    )\n",
       "    (box_head): ModuleList(\n",
       "      (0-2): 3 x FastRCNNConvFCHead(\n",
       "        (conv1): Conv2d(\n",
       "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "          (norm): LayerNorm()\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "        (conv2): Conv2d(\n",
       "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "          (norm): LayerNorm()\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "        (conv3): Conv2d(\n",
       "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "          (norm): LayerNorm()\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "        (conv4): Conv2d(\n",
       "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "          (norm): LayerNorm()\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "        (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "        (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "        (fc_relu1): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (box_predictor): ModuleList(\n",
       "      (0-2): 3 x FastRCNNOutputLayers(\n",
       "        (cls_score): Linear(in_features=1024, out_features=5, bias=True)\n",
       "        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (mask_pooler): ROIPooler(\n",
       "      (level_poolers): ModuleList(\n",
       "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
       "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
       "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
       "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
       "      )\n",
       "    )\n",
       "    (mask_head): MaskRCNNConvUpsampleHead(\n",
       "      (mask_fcn1): Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "      (mask_fcn2): Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "      (mask_fcn3): Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "      (mask_fcn4): Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (deconv_relu): ReLU()\n",
       "      (predictor): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger = setup_logger()\n",
    "cfg = setup()\n",
    "model = instantiate(cfg.model)\n",
    "model.to(cfg.train.device)\n",
    "checkpointer = DetectionCheckpointer(model)\n",
    "checkpointer.load('model.pth')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69df3c02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-09T16:06:31.101042Z",
     "iopub.status.busy": "2023-07-09T16:06:31.100306Z",
     "iopub.status.idle": "2023-07-09T16:06:31.107666Z",
     "shell.execute_reply": "2023-07-09T16:06:31.106760Z"
    },
    "papermill": {
     "duration": 0.025862,
     "end_time": "2023-07-09T16:06:31.109694",
     "exception": false,
     "start_time": "2023-07-09T16:06:31.083832",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rle_encode(mask):\n",
    "    pixels = mask.T.flatten()\n",
    "    use_padding = False\n",
    "    if pixels[0] or pixels[-1]:\n",
    "        use_padding = True\n",
    "        pixel_padded = np.zeros([len(pixels) + 2], dtype=pixels.dtype)\n",
    "        pixel_padded[1:-1] = pixels\n",
    "        pixels = pixel_padded\n",
    "    rle = np.where(pixels[1:] != pixels[:-1])[0] + 2\n",
    "    if use_padding:\n",
    "        rle = rle - 1\n",
    "    rle[1::2] = rle[1::2] - rle[:-1:2]\n",
    "    return ' '.join(str(x) for x in rle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61b7fe59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-09T16:06:31.141743Z",
     "iopub.status.busy": "2023-07-09T16:06:31.141466Z",
     "iopub.status.idle": "2023-07-09T16:06:31.147865Z",
     "shell.execute_reply": "2023-07-09T16:06:31.146921Z"
    },
    "papermill": {
     "duration": 0.025051,
     "end_time": "2023-07-09T16:06:31.149900",
     "exception": false,
     "start_time": "2023-07-09T16:06:31.124849",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from detectron2.utils.memory import retry_if_cuda_oom\n",
    "\n",
    "thing_classes = ['paragraph', 'text_box', 'image', 'table']\n",
    "@retry_if_cuda_oom\n",
    "def get_masks(prediction):\n",
    "    # get masks for each category\n",
    "    take = prediction.scores >= ACCEPTANCE_THRESHOLD\n",
    "    pred_masks = (prediction.pred_masks[take] != 0)\n",
    "    pred_classes = prediction.pred_classes[take]\n",
    "  \n",
    "    rles = []\n",
    "    for cat in range(len(thing_classes)):\n",
    "        pred_mask = pred_masks[pred_classes == cat]\n",
    "        \n",
    "        # pred_mask = retry_if_cuda_oom(torch.any)(pred_mask, dim=0)\n",
    "        pred_mask = torch.any(pred_mask, dim=0)\n",
    "        rles.append(rle_encode(pred_mask.short().to(\"cpu\").numpy()))\n",
    "\n",
    "    return rles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2f7bdf9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-09T16:06:31.181958Z",
     "iopub.status.busy": "2023-07-09T16:06:31.180558Z",
     "iopub.status.idle": "2023-07-09T16:06:31.187321Z",
     "shell.execute_reply": "2023-07-09T16:06:31.186478Z"
    },
    "papermill": {
     "duration": 0.024476,
     "end_time": "2023-07-09T16:06:31.189334",
     "exception": false,
     "start_time": "2023-07-09T16:06:31.164858",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_inference(data):\n",
    "    results = []\n",
    "    with torch.no_grad():\n",
    "        outputs = model(data)\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.synchronize()\n",
    "\n",
    "        for idx, output in enumerate(outputs):\n",
    "            output = output[\"instances\"]\n",
    "\n",
    "            rles = get_masks(output)\n",
    "\n",
    "            result = [\n",
    "                f\"{data[idx]['image_id']}_{cat},{rles[cat]}\\n\"\n",
    "                for cat in range(len(thing_classes))\n",
    "            ]\n",
    "\n",
    "            results.extend(result)\n",
    "\n",
    "        del outputs, output\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca50f81a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-09T16:06:31.220361Z",
     "iopub.status.busy": "2023-07-09T16:06:31.220106Z",
     "iopub.status.idle": "2023-07-09T17:53:26.708086Z",
     "shell.execute_reply": "2023-07-09T17:53:26.706225Z"
    },
    "papermill": {
     "duration": 6415.506218,
     "end_time": "2023-07-09T17:53:26.710476",
     "exception": false,
     "start_time": "2023-07-09T16:06:31.204258",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### RUNNING INFERENCE ON TEST DATA ####\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/09 16:06:31 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[07/09 16:06:31 d2.data.datasets.coco]: \u001b[0mLoaded 13000 images in COCO format from /kaggle/input/dlsprint2/badlad/badlad-test-metadata.json\n",
      "\u001b[32m[07/09 16:06:31 d2.data.build]: \u001b[0mDistribution of instances among all 4 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "| paragraph  | 0            |  text_box  | 0            |   image    | 0            |\n",
      "|   table    | 0            |            |              |            |              |\n",
      "|   total    | 0            |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[07/09 16:06:31 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=1024)]\n",
      "\u001b[32m[07/09 16:06:31 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[07/09 16:06:31 d2.data.common]: \u001b[0mSerializing 13000 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/09 16:06:31 d2.data.common]: \u001b[0mSerialized dataset takes 2.07 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/13000 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/native/TensorShape.cpp:3483.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "  0%|          | 1/13000 [00:07<25:36:21,  7.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference on batch 0/13000 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 251/13000 [02:17<2:20:09,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference on batch 250/13000 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 501/13000 [04:32<1:45:49,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference on batch 500/13000 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 751/13000 [07:00<2:02:40,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference on batch 750/13000 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 1001/13000 [10:12<1:42:41,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference on batch 1000/13000 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 1251/13000 [12:11<1:43:32,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference on batch 1250/13000 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 1501/13000 [13:52<1:12:13,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference on batch 1500/13000 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 1751/13000 [15:36<1:15:05,  2.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference on batch 1750/13000 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 2001/13000 [17:23<1:13:28,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference on batch 2000/13000 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 2251/13000 [19:25<2:31:50,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference on batch 2250/13000 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 2501/13000 [21:30<1:16:33,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference on batch 2500/13000 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 2751/13000 [23:24<1:07:52,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference on batch 2750/13000 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 3001/13000 [25:20<1:08:11,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference on batch 3000/13000 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 3251/13000 [27:36<1:02:26,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference on batch 3250/13000 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 3501/13000 [30:30<2:51:43,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference on batch 3500/13000 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 3751/13000 [33:55<1:06:24,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference on batch 3750/13000 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 4001/13000 [36:44<58:10,  2.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference on batch 4000/13000 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 4251/13000 [39:50<2:18:49,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference on batch 4250/13000 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 4501/13000 [42:49<1:47:13,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference on batch 4500/13000 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 4751/13000 [45:47<2:14:03,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference on batch 4750/13000 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 5001/13000 [48:36<49:19,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference on batch 5000/13000 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 5251/13000 [50:36<58:44,  2.20it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference on batch 5250/13000 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 5501/13000 [52:30<56:31,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference on batch 5500/13000 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 5751/13000 [54:22<58:07,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference on batch 5750/13000 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 6001/13000 [56:30<50:16,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference on batch 6000/13000 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 6251/13000 [58:22<45:37,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference on batch 6250/13000 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 6501/13000 [1:00:09<43:33,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference on batch 6500/13000 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 6751/13000 [1:01:57<45:00,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference on batch 6750/13000 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 7001/13000 [1:03:50<38:09,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference on batch 7000/13000 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 7251/13000 [1:05:38<43:03,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference on batch 7250/13000 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 7501/13000 [1:07:22<34:55,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference on batch 7500/13000 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 7751/13000 [1:09:06<33:38,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference on batch 7750/13000 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 8001/13000 [1:10:53<45:25,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference on batch 8000/13000 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 8251/13000 [1:12:43<32:04,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference on batch 8250/13000 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 8501/13000 [1:14:37<32:12,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference on batch 8500/13000 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 8751/13000 [1:16:24<26:37,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference on batch 8750/13000 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 9001/13000 [1:18:11<28:10,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference on batch 9000/13000 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 9251/13000 [1:19:59<31:20,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference on batch 9250/13000 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 9501/13000 [1:21:43<28:46,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference on batch 9500/13000 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 9751/13000 [1:23:38<22:22,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference on batch 9750/13000 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 10001/13000 [1:25:25<21:47,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference on batch 10000/13000 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 10251/13000 [1:27:22<18:01,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference on batch 10250/13000 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 10501/13000 [1:29:12<15:40,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference on batch 10500/13000 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 10751/13000 [1:30:57<15:55,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference on batch 10750/13000 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 11001/13000 [1:32:53<13:56,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference on batch 11000/13000 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 11251/13000 [1:34:46<19:28,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference on batch 11250/13000 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 11501/13000 [1:36:30<11:22,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference on batch 11500/13000 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 11751/13000 [1:38:17<07:56,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference on batch 11750/13000 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 12001/13000 [1:40:01<06:13,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference on batch 12000/13000 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 12251/13000 [1:41:42<04:41,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference on batch 12250/13000 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 12501/13000 [1:43:29<03:28,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference on batch 12500/13000 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 12751/13000 [1:45:12<01:31,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference on batch 12750/13000 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13000/13000 [1:46:54<00:00,  2.03it/s]\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "from tqdm import tqdm\n",
    "print(\"#### RUNNING INFERENCE ON TEST DATA ####\")\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "BATCH = 2\n",
    "\n",
    "submission_file = open(\"submission.csv\", \"w\")\n",
    "submission_file.write(\"Id,Predicted\\n\")\n",
    "\n",
    "results: list[str] = []\n",
    "test_loader = instantiate(cfg.dataloader.test)\n",
    "for i, data in enumerate(tqdm(test_loader)):\n",
    "    res = run_inference(data)\n",
    "    results.extend(res)\n",
    "\n",
    "    if i % (500 // BATCH) == 0:\n",
    "        print(f\"Inference on batch {i}/{len(test_loader)} done\")\n",
    "        submission_file.writelines(results)\n",
    "        results = []\n",
    "\n",
    "submission_file.writelines(results)\n",
    "submission_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e359e6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-09T17:53:28.678938Z",
     "iopub.status.busy": "2023-07-09T17:53:28.677881Z",
     "iopub.status.idle": "2023-07-09T17:53:28.686821Z",
     "shell.execute_reply": "2023-07-09T17:53:28.685949Z"
    },
    "papermill": {
     "duration": 0.996653,
     "end_time": "2023-07-09T17:53:28.688882",
     "exception": false,
     "start_time": "2023-07-09T17:53:27.692229",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='submission.csv' target='_blank'>submission.csv</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/submission.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "if Path(\"submission.csv\").exists:\n",
    "    display(FileLink(\"submission.csv\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6666.586305,
   "end_time": "2023-07-09T17:53:32.512023",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-07-09T16:02:25.925718",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
